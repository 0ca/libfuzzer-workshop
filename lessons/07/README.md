# Lesson 07

Here we will be fuzzing [libxml2]. During this lesson we will:
* see an importance of dictionaries
* learn how to minimize the corpus
* generate coverage report


### Build the library

```bash
cd libxml2
./autogen.sh

export FUZZ_CXXFLAGS="-O2 -fno-omit-frame-pointer -g -fsanitize=address \
    -fsanitize-coverage=edge,indirect-calls,8bit-counters,trace-cmp,trace-div,trace-gep"

CXX="clang++ $FUZZ_CXXFLAGS" CC="clang $FUZZ_CXXFLAGS" \
    CCLD="clang++ $FUZZ_CXXFLAGS"  ./configure
make -j$(nproc)
```

### Build the first fuzzer

Take a look at the following fuzzer:

```cpp
#include "libxml/parser.h"

void ignore (void* ctx, const char* msg, ...) {
  // Error handler to avoid spam of error messages from libxml parser.
}

extern "C" int LLVMFuzzerTestOneInput(const uint8_t* data, size_t size) {
  xmlSetGenericErrorFunc(NULL, &ignore);

  if (auto doc = xmlReadMemory(reinterpret_cast<const char*>(data),
                               static_cast<int>(size), "noname.xml", NULL, 0)) {
    xmlFreeDoc(doc);
  }

  return 0;
}
```

Then build it:

```bash
cd ..
clang++ -std=c++11 xml_read_memory_fuzzer.cc $FUZZ_CXXFLAGS -I libxml2/include \
    libxml2/.libs/libxml2.a ../../libFuzzer/libFuzzer.a -lz \
    -o xml_read_memory_fuzzer
```

### Run the fuzzer with and without a dictionary

Run the fuzzer on empty corpus for 5 minutes (`-max_total_time=300`):

```bash
mkdir corpus1
./xml_read_memory_fuzzer -max_total_time=300 -print_final_stats=1 corpus1
```

Open a new terminal and run the fuzzing on empty corpus again, but also add a
dictionary (`-dict=`):

```bash
mkdir corpus2
./xml_read_memory_fuzzer -dict=./xml.dict -max_total_time=300 \
    -print_final_stats=1 corpus2
```

Compare output of both processes while they are running. You should see that the
second process gets the same coverage as the first one and then overrun it very
quickly. This is an impact of dictionary used.


### Corpus and coverage

The first process terminates somewhere at:

```
#1975901  DONE   cov: 1736 ft: 5795 corp: 1544/75Kb exec/s: 6564 rss: 494Mb
```

Let's minimize its corpus (using `-merge=1` flag):

```bash
mkdir corpus1_min
./xml_read_memory_fuzzer -merge=1 corpus1_min corpus1
```

The output looks like:

```bash
INFO: Seed: 1508800405
INFO: Loaded 1 modules (79184 guards): [0xd017e0, 0xd4ed20), 
INFO: -max_len is not provided, using 1048576
Loaded 1024/1539 files from corpus1
=== Merging extra 1539 units
#1539 MIN0   cov: 1723 ft: 5810 units: 1008 exec/s: 0 rss: 95Mb
#2547 MIN1   cov: 1724 ft: 5764 units: 987 exec/s: 0 rss: 125Mb
#3534 MIN2   cov: 1724 ft: 5765 units: 975 exec/s: 0 rss: 154Mb
#4509 MIN3   cov: 1724 ft: 5763 units: 971 exec/s: 0 rss: 183Mb
=== Merge: written 971 units
```

That means that libFuzzer made `971` testcase out of `1539` at the same code
coverage.

To get some understanding of inputs generated by the fuzzer from scratch, let's
brielfy go through the corpus:

```bash
strings corpus1_min/* | more
```

The second process terminates somewhere at:

```
#2317811  DONE   cov: 2873 ft: 8005 corp: 2359/121Kb exec/s: 7700 rss: 438Mb
```

The coverage is significantly higher comparing with the first process output.

Let's minimize its corpus as well:

```bash
mkdir corpus2_min
./xml_read_memory_fuzzer -merge=1 corpus2_min corpus2
```

The output:

```bash
INFO: Seed: 2449634923
INFO: Loaded 1 modules (79184 guards): [0xd017e0, 0xd4ed20), 
INFO: -max_len is not provided, using 1048576
Loaded 1024/2356 files from corpus2
Loaded 2048/2356 files from corpus2
=== Merging extra 2356 units
#2356 MIN0   cov: 2829 ft: 8012 units: 1571 exec/s: 0 rss: 126Mb
#3927 MIN1   cov: 2830 ft: 7970 units: 1516 exec/s: 0 rss: 169Mb
#5443 MIN2   cov: 2830 ft: 7969 units: 1503 exec/s: 0 rss: 210Mb
#6946 MIN3   cov: 2830 ft: 7968 units: 1496 exec/s: 6946 rss: 250Mb
#8442 MIN4   cov: 2830 ft: 7967 units: 1494 exec/s: 8442 rss: 291Mb
=== Merge: written 1494 units
```

And quickly go through the inputs generated by the fuzzer with a dictionary:

```bash
strings corpus2_min/* | more
```

### Generate coverage report

```bash
ASAN_OPTIONS=coverage=1 ./xml_read_memory_fuzzer corpus1_min -runs=0
```

This command should generate `.sancov` file in your working directory:

```bash
$ ls *.sancov
xml_read_memory_fuzzer.26851.sancov
```

Then we need to convert that binary file to a symbolized `.symcov` file:

```bash
sancov -symbolize xml_read_memory_fuzzer xml_read_memory_fuzzer.26851.sancov \
    > xml_read_memory_fuzzer.symcov
```

To see the coverage report with user-friendly interface, let's launch local
[coverage report server]:

```bash
python3 coverage-report-server.py --symcov xml_read_memory_fuzzer.symcov \
    --srcpath libxml2
```

Open [localhost:8001](http://localhost:8001/) in your browser to see the report.


Let's generate coverage report for the second corpus (generated with dictionary)
and compare both reports by eyes. Open new terminal and do the same stuff:

```bash
ASAN_OPTIONS=coverage=1 ./xml_read_memory_fuzzer corpus2_min -runs=0

sancov -symbolize xml_read_memory_fuzzer <NEW_.SANCOV_FILE_PATH> \
    > xml_read_memory_fuzzer_2.symcov

python3 coverage-report-server.py --symcov xml_read_memory_fuzzer_2.symcov \
    --srcpath libxml2 --port 8002
```

Go to [localhost:8002](http://localhost:8002/).

The second report obviously has higher percentage of coverage for the same files
and even more source code files covered.


[coverage report server]: http://llvm.org/svn/llvm-project/llvm/trunk/tools/sancov/coverage-report-server.py
[libxml2]: http://www.xmlsoft.org/
